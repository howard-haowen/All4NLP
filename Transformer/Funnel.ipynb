{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_depth_string(depth_str):\n",
    "  depth_config = depth_str.split(\"x\")\n",
    "  if len(depth_config) == 1:\n",
    "    depth_config.append(1)\n",
    "  assert len(depth_config) == 2, \"Require two-element depth config.\"\n",
    "\n",
    "  return list(map(int, depth_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = \"6-3x2-3x2\"\n",
    "# block_size = \"8-8-8\"\n",
    "block_size = \"4-4-4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4', '4', '4'] 3\n",
      "[4, 1]\n",
      "[4, 1]\n",
      "[4, 1]\n"
     ]
    }
   ],
   "source": [
    "block_size = block_size.split(\"-\")\n",
    "n_block = len(block_size)\n",
    "block_rep = []\n",
    "block_param = []\n",
    "print(block_size, n_block)\n",
    "for i, _ in enumerate(block_size):\n",
    "  block_size_i = parse_depth_string(block_size[i])\n",
    "  print(block_size_i)\n",
    "  block_param.append(block_size_i[0])\n",
    "  block_rep.append(block_size_i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 4]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['FunnelLayer', 'FunnelLayer', 'FunnelLayer', 'FunnelLayer'],\n",
       " ['FunnelLayer', 'FunnelLayer', 'FunnelLayer', 'FunnelLayer'],\n",
       " ['FunnelLayer', 'FunnelLayer', 'FunnelLayer', 'FunnelLayer']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    [\"FunnelLayer\" for _ in range(block_size)]\n",
    "    for block_index, block_size in enumerate(block_param)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "from transformers import FunnelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = FunnelConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunnelConfig {\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"attention_type\": \"relative_shift\",\n",
       "  \"block_repeats\": [\n",
       "    1,\n",
       "    1,\n",
       "    1\n",
       "  ],\n",
       "  \"block_sizes\": [\n",
       "    4,\n",
       "    4,\n",
       "    4\n",
       "  ],\n",
       "  \"d_head\": 64,\n",
       "  \"d_inner\": 3072,\n",
       "  \"d_model\": 768,\n",
       "  \"hidden_act\": \"gelu_new\",\n",
       "  \"hidden_dropout\": 0.1,\n",
       "  \"initializer_range\": 0.1,\n",
       "  \"initializer_std\": null,\n",
       "  \"layer_norm_eps\": 1e-09,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"funnel\",\n",
       "  \"n_head\": 12,\n",
       "  \"num_decoder_layers\": 2,\n",
       "  \"pool_q_only\": true,\n",
       "  \"pooling_type\": \"mean\",\n",
       "  \"separate_cls\": true,\n",
       "  \"truncate_seq\": true,\n",
       "  \"type_vocab_size\": 3,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunnelEmbeddings(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.word_embeddings = nn.Embedding(config.vocab_size, config.hidden_size, padding_idx=config.pad_token_id)\n",
    "        self.layer_norm = nn.LayerNorm(config.d_model, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout)\n",
    "\n",
    "    def forward(self, input_ids=None, inputs_embeds=None):\n",
    "        if inputs_embeds is None:\n",
    "            inputs_embeds = self.word_embeddings(input_ids)\n",
    "        embeddings = self.layer_norm(inputs_embeds)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = FunnelEmbeddings(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = torch.LongTensor([[101, 2057, 1012, 102], [101, 1, 2, 102]])\n",
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeds = fe(input_ids)\n",
    "input_embeds.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = torch.ones(input_ids.shape, device=input_ids.device)\n",
    "attention_mask = attention_mask.type_as(input_embeds)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_type_ids = torch.zeros(\n",
    "    input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
    "token_type_ids.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type, Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_type_ids_to_mat(token_type_ids):\n",
    "    \"\"\"Convert `token_type_ids` to `token_type_mat`.\"\"\"\n",
    "    token_type_mat = token_type_ids[:, :, None] == token_type_ids[:, None]\n",
    "    # Treat <cls> as in the same segment as both A & B\n",
    "    cls_ids = token_type_ids == 2\n",
    "    cls_mat = cls_ids[:, :, None] | cls_ids[:, None]\n",
    "    return cls_mat | token_type_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = input_embeds.size(1)\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_type_mat = token_type_ids_to_mat(token_type_ids)\n",
    "token_type_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 768])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_type_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_mask = (\n",
    "    F.pad(input_embeds.new_ones([seq_len - 1, seq_len - 1]), (1, 0, 1, 0))\n",
    ")\n",
    "cls_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.],\n",
       "        [0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 511])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(100, [2, 511])\n",
    "print(x.shape)\n",
    "xx = x[:, None, :, None]\n",
    "xxx = F.avg_pool2d(xx, (2,1), stride=(2,1), ceil_mode=True)\n",
    "xxx[:, 0, :, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 511, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 768])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(100, [2, 511, 768])\n",
    "print(x.shape)\n",
    "xx = x[:, None, :, :]\n",
    "xxx = F.avg_pool2d(xx, (2,1), stride=(2,1), ceil_mode=True)\n",
    "xxx[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeds.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = input_embeds\n",
    "xx = x[:, None, :, :]\n",
    "xxx = F.avg_pool2d(xx, (2,1), stride=(2,1), ceil_mode=True)\n",
    "xxx[:, 0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_pos(pos, stride, pooled_pos=None, shift=1):\n",
    "    \"\"\"\n",
    "    Build the relative positional vector between `pos` and `pooled_pos`.\n",
    "    \"\"\"\n",
    "    if pooled_pos is None:\n",
    "        pooled_pos = pos\n",
    "\n",
    "    ref_point = pooled_pos[0] - pos[0]\n",
    "    num_remove = shift * len(pooled_pos)\n",
    "    max_dist = ref_point + num_remove * stride\n",
    "    min_dist = pooled_pos[0] - pos[-1]\n",
    "\n",
    "    return torch.arange(max_dist, min_dist - 1, -stride, dtype=torch.long, device=pos.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stride_pool_pos(pos_id, block_index):\n",
    "    \"\"\"\n",
    "    Pool `pos_id` while keeping the cls token separate (if `config.separate_cls=True`).\n",
    "    \"\"\"\n",
    "    if config.separate_cls:\n",
    "        # Under separate <cls>, we treat the <cls> as the first token in\n",
    "        # the previous block of the 1st real block. Since the 1st real\n",
    "        # block always has position 1, the position of the previous block\n",
    "        # will be at `1 - 2 ** block_index`.\n",
    "        cls_pos = pos_id.new_tensor([-(2 ** block_index) + 1])\n",
    "        pooled_pos_id = pos_id[1:-1] if config.truncate_seq else pos_id[1:]\n",
    "        return torch.cat([cls_pos, pooled_pos_id[::2]], 0)\n",
    "    else:\n",
    "        return pos_id[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position_embeds(seq_len, dtype, device):\n",
    "    \"\"\"\n",
    "    Create and cache inputs related to relative position encoding. Those are very different depending on whether we\n",
    "    are using the factorized or the relative shift attention:\n",
    "\n",
    "    For the factorized attention, it returns the matrices (phi, pi, psi, omega) used in the paper, appendix A.2.2,\n",
    "    final formula.\n",
    "\n",
    "    For the relative shif attention, it returns all possible vectors R used in the paper, appendix A.2.1, final\n",
    "    formula.\n",
    "\n",
    "    Paper link: https://arxiv.org/abs/2006.03236\n",
    "    \"\"\"\n",
    "    d_model = config.d_model\n",
    "    if config.attention_type == \"factorized\":\n",
    "        # Notations from the paper, appending A.2.2, final formula.\n",
    "        # We need to create and return the matrics phi, psi, pi and omega.\n",
    "        pos_seq = torch.arange(0, seq_len, 1.0, dtype=dtype, device=device)\n",
    "        freq_seq = torch.arange(0, d_model // 2, 1.0, dtype=dtype, device=device)\n",
    "        inv_freq = 1 / (10000 ** (freq_seq / (d_model // 2)))\n",
    "        sinusoid = pos_seq[:, None] * inv_freq[None]\n",
    "        sin_embed = torch.sin(sinusoid)\n",
    "        sin_embed_d = nn.Dropout(config.hidden_dropout)(sin_embed)\n",
    "        cos_embed = torch.cos(sinusoid)\n",
    "        cos_embed_d = nn.Dropout(config.hidden_dropout)(cos_embed)\n",
    "        # This is different from the formula on the paper...\n",
    "        phi = torch.cat([sin_embed_d, sin_embed_d], dim=-1)\n",
    "        psi = torch.cat([cos_embed, sin_embed], dim=-1)\n",
    "        pi = torch.cat([cos_embed_d, cos_embed_d], dim=-1)\n",
    "        omega = torch.cat([-sin_embed, cos_embed], dim=-1)\n",
    "        return (phi, pi, psi, omega)\n",
    "    else:\n",
    "        # Notations from the paper, appending A.2.1, final formula.\n",
    "        # We need to create and return all the possible vectors R for all blocks and shifts.\n",
    "        freq_seq = torch.arange(0, d_model // 2, 1.0, dtype=dtype, device=device)\n",
    "        inv_freq = 1 / (10000 ** (freq_seq / (d_model // 2)))\n",
    "        # Maximum relative positions for the first input\n",
    "        rel_pos_id = torch.arange(-seq_len * 2, seq_len * 2, 1.0, dtype=dtype, device=device)\n",
    "        zero_offset = seq_len * 2\n",
    "        sinusoid = rel_pos_id[:, None] * inv_freq[None]\n",
    "        sin_embed = nn.Dropout(config.hidden_dropout)(torch.sin(sinusoid))\n",
    "        cos_embed = nn.Dropout(config.hidden_dropout)(torch.cos(sinusoid))\n",
    "        pos_embed = torch.cat([sin_embed, cos_embed], dim=-1)\n",
    "\n",
    "        pos = torch.arange(0, seq_len, dtype=dtype, device=device)\n",
    "        xpos = pos\n",
    "        pooled_pos = pos\n",
    "        position_embeds_list = []\n",
    "        for block_index in range(0, config.num_blocks):\n",
    "            # For each block with block_index > 0, we need two types position embeddings:\n",
    "            #   - Attention(pooled-q, unpooled-kv)\n",
    "            #   - Attention(pooled-q, pooled-kv)\n",
    "            # For block_index = 0 we only need the second one and leave the first one as None.\n",
    "\n",
    "            # First type\n",
    "            if block_index == 0:\n",
    "                position_embeds_pooling = None\n",
    "            else:\n",
    "                pooled_pos = stride_pool_pos(pos, block_index)\n",
    "\n",
    "                # construct rel_pos_id\n",
    "                stride = 2 ** (block_index - 1)\n",
    "                rel_pos = relative_pos(pos, stride, pooled_pos, shift=2)\n",
    "                print(\"FirstType rel pos\", rel_pos)\n",
    "                rel_pos = rel_pos[:, None] + zero_offset\n",
    "                rel_pos = rel_pos.expand(rel_pos.size(0), d_model)\n",
    "                position_embeds_pooling = torch.gather(pos_embed, 0, rel_pos)\n",
    "\n",
    "            # Second type\n",
    "            pos = pooled_pos\n",
    "            stride = 2 ** block_index\n",
    "            rel_pos = relative_pos(pos, stride)\n",
    "            print(\"SecondType rel pos\", rel_pos)\n",
    "\n",
    "            rel_pos = rel_pos[:, None] + zero_offset\n",
    "            rel_pos = rel_pos.expand(rel_pos.size(0), d_model)\n",
    "            position_embeds_no_pooling = torch.gather(pos_embed, 0, rel_pos)\n",
    "\n",
    "            position_embeds_list.append([position_embeds_no_pooling, position_embeds_pooling])\n",
    "\n",
    "            print()\n",
    "        return position_embeds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.attention_type = \"factorized\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_embeds = get_position_embeds(\n",
    "    seq_len, input_embeds.dtype, input_embeds.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n",
      "torch.Size([4, 768])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(position_embeds)):\n",
    "    print(position_embeds[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SecondType rel pos tensor([ 4,  3,  2,  1,  0, -1, -2, -3])\n",
      "\n",
      "FirstType rel pos tensor([ 3,  2,  1,  0, -1, -2, -3, -4])\n",
      "SecondType rel pos tensor([ 4,  2,  0, -2])\n",
      "\n",
      "FirstType rel pos tensor([ 2,  0, -2, -4])\n",
      "SecondType rel pos tensor([4, 0])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config.attention_type = \"\"\n",
    "position_embeds = get_position_embeds(\n",
    "    seq_len, input_embeds.dtype, input_embeds.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 768])\n",
      "None\n",
      "\n",
      "torch.Size([4, 768])\n",
      "torch.Size([8, 768])\n",
      "\n",
      "torch.Size([2, 768])\n",
      "torch.Size([4, 768])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in position_embeds:\n",
    "    for sub in item:\n",
    "        if sub != None:\n",
    "            print(sub.shape)\n",
    "        else:\n",
    "            print(\"None\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 768\n",
    "freq_seq = torch.arange(0, d_model // 2, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_freq = 1 / (10000 ** (freq_seq / (d_model // 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_pos_id = torch.arange(-seq_len * 2, seq_len * 2, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-8., -7., -6., -5., -4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.,  5.,\n",
       "         6.,  7.])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_pos_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinusoid = rel_pos_id[:, None] * inv_freq[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 384])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinusoid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_embed = nn.Dropout(config.hidden_dropout)(torch.sin(sinusoid))\n",
    "cos_embed = nn.Dropout(config.hidden_dropout)(torch.cos(sinusoid))\n",
    "pos_embed = torch.cat([sin_embed, cos_embed], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 768])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = torch.arange(0, seq_len)\n",
    "pooled_pos = pos\n",
    "position_embeds_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1])\n",
      "tensor([-1,  1])\n",
      "tensor([-3,  1])\n",
      "tensor([-7,  1])\n"
     ]
    }
   ],
   "source": [
    "for i in range((seq_len)):\n",
    "    pooled_pos = stride_pool_pos(pos, i)\n",
    "    print(pooled_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.separate_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-7,  1])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_pos = pos.new_tensor([-(2 ** 3) + 1])\n",
    "pooled_pos_id = pos[1:-1]\n",
    "torch.cat([cls_pos, pooled_pos_id[::2]], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-7])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 768])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_point:  tensor(-1)\n",
      "num_remove:  4\n",
      "tensor(3) tensor(-4)\n",
      "pooled_pos:  tensor([-1,  1])\n",
      "stride:  1\n",
      "rel_pos:  tensor([ 3,  2,  1,  0, -1, -2, -3, -4])\n",
      "torch.Size([8, 1])\n",
      "torch.Size([8, 768])\n",
      "torch.Size([8, 768])\n",
      "\n",
      "ref_point:  tensor(-3)\n",
      "num_remove:  4\n",
      "tensor(5) tensor(-6)\n",
      "pooled_pos:  tensor([-3,  1])\n",
      "stride:  2\n",
      "rel_pos:  tensor([ 5,  3,  1, -1, -3, -5])\n",
      "torch.Size([6, 1])\n",
      "torch.Size([6, 768])\n",
      "torch.Size([6, 768])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for block_index in range(1, 3):\n",
    "    pooled_pos = stride_pool_pos(pos, block_index)\n",
    "    stride = 2 ** (block_index - 1)\n",
    "    rel_pos = relative_pos(pos, stride, pooled_pos, shift=2)\n",
    "    print(\"pooled_pos: \", pooled_pos)\n",
    "    print(\"stride: \", stride)\n",
    "    print(\"rel_pos: \", rel_pos)\n",
    "    \n",
    "    zero_offset = seq_len * 2\n",
    "\n",
    "    rel_pos = rel_pos[:, None] + zero_offset\n",
    "    print(rel_pos.shape)\n",
    "    rel_pos = rel_pos.expand(rel_pos.size(0), d_model)\n",
    "    print(rel_pos.shape)\n",
    "    position_embeds_pooling = torch.gather(pos_embed, 0, rel_pos)\n",
    "    print(position_embeds_pooling.shape)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_pos(pos, stride, pooled_pos=None, shift=1):\n",
    "        if pooled_pos is None:\n",
    "            pooled_pos = pos\n",
    "\n",
    "        ref_point = pooled_pos[0] - pos[0]\n",
    "        print(\"ref_point: \", ref_point)\n",
    "        num_remove = shift * len(pooled_pos)\n",
    "        print(\"num_remove: \", num_remove)\n",
    "        max_dist = ref_point + num_remove * stride\n",
    "        min_dist = pooled_pos[0] - pos[-1]\n",
    "        print(max_dist, min_dist)\n",
    "        return torch.arange(max_dist, min_dist - 1, -stride, dtype=torch.long, device=pos.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref_point:  tensor(-3)\n",
      "num_remove:  6\n",
      "tensor(3) tensor(-6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 3,  2,  1,  0, -1, -2, -3, -4, -5, -6])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_pos(pos, 1, [-3, 1], shift=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mean'"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.pooling_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.pool_q_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True, True],\n",
       "         [True, True, True, True],\n",
       "         [True, True, True, True],\n",
       "         [True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True],\n",
       "         [True, True, True, True],\n",
       "         [True, True, True, True],\n",
       "         [True, True, True, True]]])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_type_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 4])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_type_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    " def stride_pool( tensor, axis):\n",
    "        \"\"\"\n",
    "        Perform pooling by stride slicing the tensor along the given axis.\n",
    "        \"\"\"\n",
    "        if tensor is None:\n",
    "            return None\n",
    "\n",
    "        # Do the stride pool recursively if axis is a list or a tuple of ints.\n",
    "        if isinstance(axis, (list, tuple)):\n",
    "            for ax in axis:\n",
    "                tensor = self.stride_pool(tensor, ax)\n",
    "            return tensor\n",
    "\n",
    "        # Do the stride pool recursively if tensor is a list or tuple of tensors.\n",
    "        if isinstance(tensor, (tuple, list)):\n",
    "            return type(tensor)(self.stride_pool(x, axis) for x in tensor)\n",
    "\n",
    "        # Deal with negative axis\n",
    "        axis %= tensor.ndim\n",
    "\n",
    "        axis_slice = (\n",
    "            slice(None, -1, 2) if config.separate_cls and config.truncate_seq else slice(None, None, 2)\n",
    "        )\n",
    "        enc_slice = [slice(None)] * axis + [axis_slice]\n",
    "        if config.separate_cls:\n",
    "            cls_slice = [slice(None)] * axis + [slice(None, 1)]\n",
    "            tensor = torch.cat([tensor[cls_slice], tensor], axis=axis)\n",
    "        return tensor[enc_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True, True],\n",
       "         [True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True],\n",
       "         [True, True, True, True]]])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stride_pool(token_type_mat, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 4])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stride_pool(cls_mask, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stride_pool(torch.LongTensor([[101, 2057, 1012, 102, 101], [101, 1, 2, 102, 101]]), 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor([[101, 2057, 1012, 102], [101, 1, 2, 102]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_tensor(tensor, mode=\"mean\", stride=2):\n",
    "        \"\"\"Apply 1D pooling to a tensor of size [B x T (x H)].\"\"\"\n",
    "        if tensor is None:\n",
    "            return None\n",
    "\n",
    "        # Do the pool recursively if tensor is a list or tuple of tensors.\n",
    "        if isinstance(tensor, (tuple, list)):\n",
    "            return type(tensor)(pool_tensor(tensor, mode=mode, stride=stride) for x in tensor)\n",
    "\n",
    "        if config.separate_cls:\n",
    "            suffix = tensor[:, :-1] if config.truncate_seq else tensor\n",
    "            tensor = torch.cat([tensor[:, :1], suffix], dim=1)\n",
    "\n",
    "        ndim = tensor.ndim\n",
    "        if ndim == 2:\n",
    "            tensor = tensor[:, None, :, None]\n",
    "        elif ndim == 3:\n",
    "            tensor = tensor[:, None, :, :]\n",
    "        # Stride is applied on the second-to-last dimension.\n",
    "        stride = (stride, 1)\n",
    "\n",
    "        if mode == \"mean\":\n",
    "            tensor = F.avg_pool2d(tensor, stride, stride=stride, ceil_mode=True)\n",
    "        elif mode == \"max\":\n",
    "            tensor = F.max_pool2d(tensor, stride, stride=stride, ceil_mode=True)\n",
    "        elif mode == \"min\":\n",
    "            tensor = -F.max_pool2d(-tensor, stride, stride=stride, ceil_mode=True)\n",
    "        else:\n",
    "            raise NotImplementedError(\"The supported modes are 'mean', 'max' and 'min'.\")\n",
    "\n",
    "        if ndim == 2:\n",
    "            return tensor[:, 0, :, 0]\n",
    "        elif ndim == 3:\n",
    "            return tensor[:, 0]\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 1534,  102],\n",
       "        [ 101,    1,  102]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_tensor(torch.LongTensor([[101, 2057, 1012, 102, 101], [101, 1, 2, 102, 101]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 768])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor([[101, 2057, 1012, 102, 101], [101, 1, 2, 102, 101]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 4])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stride_pool(token_type_mat, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stride_pool(stride_pool(token_type_mat, 1), 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_attention_pooling( output, attention_inputs):\n",
    "    \"\"\" Pool `output` and the proper parts of `attention_inputs` before the attention layer. \"\"\"\n",
    "    position_embeds, token_type_mat, attention_mask, cls_mask = attention_inputs\n",
    "    token_type_mat = stride_pool(token_type_mat, 1)\n",
    "    cls_mask = stride_pool(cls_mask, 0)\n",
    "    output = pool_tensor(output, mode=config.pooling_type)\n",
    "    attention_inputs = (position_embeds, token_type_mat, attention_mask, cls_mask)\n",
    "    return output, attention_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 12, 64)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.d_model, config.n_head, config.d_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunnelRelMultiheadAttention(nn.Module):\n",
    "    def __init__(self, config, block_index):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.block_index = block_index\n",
    "        d_model, n_head, d_head = config.d_model, config.n_head, config.d_head\n",
    "\n",
    "        self.hidden_dropout = nn.Dropout(config.hidden_dropout)\n",
    "        self.attention_dropout = nn.Dropout(config.attention_dropout)\n",
    "\n",
    "        self.q_head = nn.Linear(d_model, n_head * d_head, bias=False)\n",
    "        self.k_head = nn.Linear(d_model, n_head * d_head)\n",
    "        self.v_head = nn.Linear(d_model, n_head * d_head)\n",
    "\n",
    "        self.r_w_bias = nn.Parameter(torch.zeros([n_head, d_head]))\n",
    "        self.r_r_bias = nn.Parameter(torch.zeros([n_head, d_head]))\n",
    "        self.r_kernel = nn.Parameter(torch.zeros([d_model, n_head, d_head]))\n",
    "        self.r_s_bias = nn.Parameter(torch.zeros([n_head, d_head]))\n",
    "        self.seg_embed = nn.Parameter(torch.zeros([2, n_head, d_head]))\n",
    "\n",
    "        self.post_proj = nn.Linear(n_head * d_head, d_model)\n",
    "        self.layer_norm = nn.LayerNorm(d_model, eps=config.layer_norm_eps)\n",
    "        self.scale = 1.0 / (d_head ** 0.5)\n",
    "    \n",
    "    def forward(self, query, key, value, attention_inputs, output_attentions=False, i=1):\n",
    "        # query has shape batch_size x seq_len x d_model\n",
    "        # key and value have shapes batch_size x context_len x d_model\n",
    "        position_embeds, token_type_mat, attention_mask, cls_mask = attention_inputs\n",
    "\n",
    "        batch_size, seq_len, _ = query.shape\n",
    "        context_len = key.shape[1]\n",
    "        n_head, d_head = self.config.n_head, self.config.d_head\n",
    "\n",
    "        # Shape batch_size x seq_len x n_head x d_head\n",
    "        q_head = self.q_head(query).view(batch_size, seq_len, n_head, d_head)\n",
    "        print(q_head.shape)\n",
    "        # Shapes batch_size x context_len x n_head x d_head\n",
    "        k_head = self.k_head(key).view(batch_size, context_len, n_head, d_head)\n",
    "        print(k_head.shape)\n",
    "        v_head = self.v_head(value).view(batch_size, context_len, n_head, d_head)\n",
    "\n",
    "        q_head = q_head * self.scale\n",
    "        # Shape n_head x d_head\n",
    "        r_w_bias = self.r_w_bias * self.scale\n",
    "        # Shapes batch_size x n_head x seq_len x context_len\n",
    "        content_score = torch.einsum(\"bind,bjnd->bnij\", q_head + r_w_bias, k_head)\n",
    "        \n",
    "        positional_attn = self.relative_positional_attention(position_embeds, q_head, context_len, cls_mask, i)\n",
    "        token_type_attn = self.relative_token_type_attention(token_type_mat, q_head, cls_mask)\n",
    "        print(\"content score: \", content_score.shape)\n",
    "        print(\"positional score: \", positional_attn.shape)\n",
    "        print(\"token_type score\", token_type_attn.shape)\n",
    "\n",
    "        # merge attention scores\n",
    "        attn_score = content_score# + positional_attn + token_type_attn\n",
    "\n",
    "        # precision safe in case of mixed precision training\n",
    "        dtype = attn_score.dtype\n",
    "        attn_score = attn_score.float()\n",
    "        # perform masking\n",
    "        if attention_mask is not None:\n",
    "            attn_score = attn_score - 1e6 * (1 - attention_mask[:, None, None].float())\n",
    "        # attention probability\n",
    "        attn_prob = torch.softmax(attn_score, dim=-1, dtype=dtype)\n",
    "        attn_prob = self.attention_dropout(attn_prob)\n",
    "\n",
    "        # attention output, shape batch_size x seq_len x n_head x d_head\n",
    "        attn_vec = torch.einsum(\"bnij,bjnd->bind\", attn_prob, v_head)\n",
    "\n",
    "        # Shape shape batch_size x seq_len x d_model\n",
    "        attn_out = self.post_proj(attn_vec.reshape(batch_size, seq_len, n_head * d_head))\n",
    "        attn_out = self.hidden_dropout(attn_out)\n",
    "\n",
    "        output = self.layer_norm(query + attn_out)\n",
    "        return (output, attn_prob) if output_attentions else (output,)\n",
    "    \n",
    "    def relative_positional_attention(self, position_embeds, q_head, context_len, cls_mask=None, i=1):\n",
    "        \"\"\" Relative attention score for the positional encodings \"\"\"\n",
    "        # q_head has shape batch_size x sea_len x n_head x d_head\n",
    "\n",
    "        shift = 2 if q_head.shape[1] != context_len else 1\n",
    "        # Notations from the paper, appending A.2.1, final formula (https://arxiv.org/abs/2006.03236)\n",
    "        # Grab the proper positional encoding, shape max_rel_len x d_model\n",
    "        r = position_embeds[i][shift - 1]\n",
    "        # Shape n_head x d_head\n",
    "        v = self.r_r_bias * self.scale\n",
    "        # Shape d_model x n_head x d_head\n",
    "        w_r = self.r_kernel\n",
    "\n",
    "        # Shape max_rel_len x n_head x d_model\n",
    "        r_head = torch.einsum(\"td,dnh->tnh\", r, w_r)\n",
    "        # Shape batch_size x n_head x seq_len x max_rel_len\n",
    "        print(\"q_head + v shape: \", (q_head + v).shape)\n",
    "        print(\"q_head: \", q_head.shape)\n",
    "        print(\"V\", v.shape)\n",
    "        positional_attn = torch.einsum(\"binh,tnh->bnit\", q_head + v, r_head)\n",
    "        # Shape batch_size x n_head x seq_len x context_len\n",
    "        print(positional_attn.shape, context_len, shift)\n",
    "        positional_attn = _relative_shift_gather(positional_attn, context_len, shift)\n",
    "        print(positional_attn.shape)\n",
    "        if cls_mask is not None:\n",
    "            positional_attn *= cls_mask\n",
    "        return positional_attn\n",
    "    \n",
    "    def relative_token_type_attention(self, token_type_mat, q, cls_mask=None):\n",
    "        # q => batch_size × context_len × n_head × d_head\n",
    "        # token_type_mat => batch_size × context_len × seq_len\n",
    "        batch_size, context_len, seq_len = token_type_mat.shape\n",
    "        r_s_bias = self.r_s_bias * self.scale\n",
    "        # batch_size × n_head × context_len × 2\n",
    "        token_type_bias = torch.einsum(\"bind,snd->bnis\", q + r_s_bias, self.seg_embed)\n",
    "        # batch_size × n_head × context_len × seq_len\n",
    "        token_type_mat = token_type_mat[:, None].expand(\n",
    "            [batch_size, q.shape[2], context_len, seq_len])\n",
    "        # batch_size × n_head × context_len\n",
    "        diff_token_type, same_token_type = torch.split(token_type_bias, 1, dim=-1)\n",
    "        # batch_size × n_head × context_len × seq_len\n",
    "        print(\"token_type_mat shape\", token_type_mat.shape)\n",
    "#         print(token_type_mat)\n",
    "        token_type_attn = torch.where(\n",
    "            token_type_mat, \n",
    "            same_token_type.expand(token_type_mat.shape),\n",
    "            diff_token_type.expand(token_type_mat.shape)\n",
    "            )\n",
    "#         print(token_type_attn)\n",
    "        if cls_mask is not None:\n",
    "            token_type_attn *= cls_mask\n",
    "        return token_type_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _relative_shift_gather(positional_attn, context_len, shift):\n",
    "    batch_size, n_head, seq_len, max_rel_len = positional_attn.shape\n",
    "    # max_rel_len = 2 * context_len + shift -1 is the numbers of possible relative positions i-j\n",
    "\n",
    "    # What's next is the same as doing the following gather, which might be clearer code but less efficient.\n",
    "    # idxs = context_len + torch.arange(0, context_len).unsqueeze(0) - torch.arange(0, seq_len).unsqueeze(1)\n",
    "    # # matrix of context_len + i-j\n",
    "    # return positional_attn.gather(3, idxs.expand([batch_size, n_head, context_len, context_len]))\n",
    "\n",
    "    positional_attn = torch.reshape(positional_attn, [batch_size, n_head, max_rel_len, seq_len])\n",
    "    positional_attn = positional_attn[:, :, shift:, :]\n",
    "    positional_attn = torch.reshape(positional_attn, [batch_size, n_head, seq_len, max_rel_len - shift])\n",
    "    positional_attn = positional_attn[..., :context_len]\n",
    "    return positional_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "fra = FunnelRelMultiheadAttention(config, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[-0.8409, -0.7684, -0.6909,  ...,  1.1111,  1.1111,  1.1111],\n",
       "          [ 0.1568,  0.2345,  0.3093,  ...,  1.1111,  1.1111,  1.1111],\n",
       "          [ 1.0103,  1.0311,  1.0492,  ...,  1.1111,  1.1111,  1.1111],\n",
       "          ...,\n",
       "          [-0.0000, -0.9205, -0.9058,  ...,  1.1111,  1.1111,  1.1111],\n",
       "          [-1.0103, -0.0000, -1.0492,  ...,  1.1111,  1.1111,  1.1111],\n",
       "          [-0.1568, -0.2345, -0.3093,  ...,  1.1111,  1.1111,  0.0000]]),\n",
       "  None],\n",
       " [tensor([[-0.8409, -0.7684, -0.6909,  ...,  1.1111,  1.1111,  1.1111],\n",
       "          [ 1.0103,  1.0311,  1.0492,  ...,  1.1111,  1.1111,  1.1111],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  1.1111,  1.1111,  1.1111],\n",
       "          [-1.0103, -0.0000, -1.0492,  ...,  1.1111,  1.1111,  1.1111]]),\n",
       "  tensor([[ 0.1568,  0.2345,  0.3093,  ...,  1.1111,  1.1111,  1.1111],\n",
       "          [ 1.0103,  1.0311,  1.0492,  ...,  1.1111,  1.1111,  1.1111],\n",
       "          [ 0.9350,  0.0000,  0.9058,  ...,  1.1111,  0.0000,  1.1111],\n",
       "          ...,\n",
       "          [-1.0103, -0.0000, -1.0492,  ...,  1.1111,  1.1111,  1.1111],\n",
       "          [-0.1568, -0.2345, -0.3093,  ...,  1.1111,  1.1111,  0.0000],\n",
       "          [ 0.8409,  0.7684,  0.6909,  ...,  1.1111,  1.1111,  1.1111]])],\n",
       " [tensor([[-0.8409, -0.7684, -0.6909,  ...,  1.1111,  1.1111,  1.1111],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  1.1111,  1.1111,  1.1111]]),\n",
       "  tensor([[ 1.0103,  1.0311,  1.0492,  ...,  1.1111,  1.1111,  1.1111],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  1.1111,  1.1111,  1.1111],\n",
       "          [-1.0103, -0.0000, -1.0492,  ...,  1.1111,  1.1111,  1.1111],\n",
       "          [ 0.8409,  0.7684,  0.6909,  ...,  1.1111,  1.1111,  1.1111]])]]"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 4]), torch.Size([2, 4]), torch.Size([1, 4]))"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_type_mat.shape, attention_mask.shape, cls_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_inputs = (position_embeds, token_type_mat, attention_mask, cls_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_hidden, attention_inputs = pre_attention_pooling(input_embeds, attention_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_embeds, token_type_mat, attention_mask, cls_mask = attention_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SecondType rel pos tensor([ 4,  3,  2,  1,  0, -1, -2, -3])\n",
      "\n",
      "FirstType rel pos tensor([ 3,  2,  1,  0, -1, -2, -3, -4])\n",
      "SecondType rel pos tensor([ 4,  2,  0, -2])\n",
      "\n",
      "FirstType rel pos tensor([ 2,  0, -2, -4])\n",
      "SecondType rel pos tensor([4, 0])\n",
      "\n",
      "torch.Size([2, 2, 12, 64])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "q_head + v shape:  torch.Size([2, 2, 12, 64])\n",
      "q_head:  torch.Size([2, 2, 12, 64])\n",
      "V torch.Size([12, 64])\n",
      "torch.Size([2, 12, 2, 8]) 4 2\n",
      "torch.Size([2, 12, 2, 4])\n",
      "token_type_mat shape torch.Size([2, 12, 2, 4])\n",
      "content score:  torch.Size([2, 12, 2, 4])\n",
      "positional score:  torch.Size([2, 12, 2, 4])\n",
      "token_type score torch.Size([2, 12, 2, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0451, -0.0450, -1.1673,  ...,  0.0464,  1.0833,  1.7608],\n",
       "         [ 1.1183, -0.5268,  1.4921,  ...,  0.5391, -0.3932, -0.4550]],\n",
       "\n",
       "        [[ 1.0034,  0.0594, -0.1742,  ...,  0.5220,  0.9122,  1.6947],\n",
       "         [-0.5062, -1.0373, -0.5044,  ...,  0.6907,  0.4824,  1.2550]]],\n",
       "       grad_fn=<NativeLayerNormBackward>)"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = FunnelConfig()\n",
    "fe = FunnelEmbeddings(config)\n",
    "input_ids = torch.LongTensor([[101, 2057, 1012, 102], [101, 1, 2, 102]])\n",
    "input_embeds = fe(input_ids)\n",
    "attention_mask = torch.ones(input_ids.shape, device=input_ids.device)\n",
    "attention_mask = attention_mask.type_as(input_embeds)\n",
    "token_type_ids = torch.zeros(input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
    "\n",
    "seq_len = input_embeds.size(1)\n",
    "token_type_mat = token_type_ids_to_mat(token_type_ids)\n",
    "cls_mask = (F.pad(input_embeds.new_ones([seq_len - 1, seq_len - 1]), (1, 0, 1, 0)))\n",
    "position_embeds = get_position_embeds(seq_len, input_embeds.dtype, input_embeds.device)\n",
    "\n",
    "attention_inputs = (position_embeds, token_type_mat, attention_mask, cls_mask)\n",
    "pooled_hidden, attention_inputs = pre_attention_pooling(input_embeds, attention_inputs)\n",
    "position_embeds, token_type_mat, attention_mask, cls_mask = attention_inputs\n",
    "\n",
    "fra = FunnelRelMultiheadAttention(config, 2)\n",
    "flh, = fra(pooled_hidden, input_embeds, input_embeds, attention_inputs, i=1)\n",
    "flh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 768])"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.num_decoder_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(x, stride, target_len, separate_cls=True, truncate_seq=False):\n",
    "    \"\"\"Upsample tensor `x` to match `target_len` by repeating the tokens `stride` time on the sequence length\n",
    "    dimension.\"\"\"\n",
    "    if stride == 1:\n",
    "        return x\n",
    "    if separate_cls:\n",
    "        cls = x[:, :1]\n",
    "        x = x[:, 1:]\n",
    "    output = torch.repeat_interleave(x, repeats=stride, dim=1)\n",
    "    if separate_cls:\n",
    "        if truncate_seq:\n",
    "            output = nn.functional.pad(output, (0, 0, 0, stride - 1, 0, 0))\n",
    "        output = output[:, : target_len - 1]\n",
    "        output = torch.cat([cls, output], dim=1)\n",
    "    else:\n",
    "        output = output[:, :target_len]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunnelPositionwiseFFN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(config.d_model, config.d_inner)\n",
    "        self.activation_function = ACT2FN[config.hidden_act]\n",
    "        self.activation_dropout = nn.Dropout(config.activation_dropout)\n",
    "        self.linear_2 = nn.Linear(config.d_inner, config.d_model)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout)\n",
    "        self.layer_norm = nn.LayerNorm(config.d_model, config.layer_norm_eps)\n",
    "\n",
    "    def forward(self, hidden):\n",
    "        h = self.linear_1(hidden)\n",
    "        h = self.activation_function(h)\n",
    "        h = self.activation_dropout(h)\n",
    "        h = self.linear_2(h)\n",
    "        h = self.dropout(h)\n",
    "        return self.layer_norm(hidden + h)\n",
    "\n",
    "\n",
    "class FunnelLayer(nn.Module):\n",
    "    def __init__(self, config, block_index):\n",
    "        super().__init__()\n",
    "        self.attention = FunnelRelMultiheadAttention(config, block_index)\n",
    "        self.ffn = FunnelPositionwiseFFN(config)\n",
    "\n",
    "    def forward(self, query, key, value, attention_inputs, output_attentions=False, i=0):\n",
    "        attn = self.attention(query, key, value, attention_inputs, output_attentions=output_attentions, i=0)\n",
    "        output = self.ffn(attn[0])\n",
    "        return (output, attn[1]) if output_attentions else (output,)\n",
    "\n",
    "import math\n",
    "def gelu_new(x):\n",
    "    \"\"\"Implementation of the gelu activation function currently in Google Bert repo (identical to OpenAI GPT).\n",
    "    Also see https://arxiv.org/abs/1606.08415\n",
    "    \"\"\"\n",
    "    return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n",
    "\n",
    "ACT2FN = {\n",
    "    \"gelu_new\": gelu_new,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunnelDecoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.layers = nn.ModuleList(\n",
    "            [FunnelLayer(config, 0) for _ in range(config.num_decoder_layers)]\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        final_hidden,\n",
    "        first_block_hidden,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None\n",
    "    ):\n",
    "        upsampled_hidden = upsample(\n",
    "            final_hidden,\n",
    "            stride=2 ** (len(self.config.block_sizes) - 1),\n",
    "            target_len=first_block_hidden.shape[1],\n",
    "            separate_cls=self.config.separate_cls,\n",
    "            truncate_seq=self.config.truncate_seq,\n",
    "        )\n",
    "\n",
    "        hidden = upsampled_hidden + first_block_hidden\n",
    "        \n",
    "        seq_len = hidden.size(1)\n",
    "        position_embeds = get_position_embeds(seq_len, hidden.dtype, hidden.device)\n",
    "        token_type_mat = token_type_ids_to_mat(token_type_ids) if token_type_ids is not None else None\n",
    "        cls_mask = (\n",
    "            F.pad(hidden.new_ones([seq_len - 1, seq_len - 1]), (1, 0, 1, 0))\n",
    "            if self.config.separate_cls\n",
    "            else None\n",
    "        )\n",
    "        attention_inputs = (position_embeds, token_type_mat, attention_mask, cls_mask)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            layer_output = layer(hidden, hidden, hidden, attention_inputs, output_attentions=False, i=0)\n",
    "            hidden = layer_output[0]\n",
    "            print(\"Final Print\", hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = FunnelDecoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SecondType rel pos tensor([ 4,  3,  2,  1,  0, -1, -2, -3])\n",
      "\n",
      "FirstType rel pos tensor([ 3,  2,  1,  0, -1, -2, -3, -4])\n",
      "SecondType rel pos tensor([ 4,  2,  0, -2])\n",
      "\n",
      "FirstType rel pos tensor([ 2,  0, -2, -4])\n",
      "SecondType rel pos tensor([4, 0])\n",
      "\n",
      "torch.Size([2, 4, 12, 64])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "q_head + v shape:  torch.Size([2, 4, 12, 64])\n",
      "q_head:  torch.Size([2, 4, 12, 64])\n",
      "V torch.Size([12, 64])\n",
      "torch.Size([2, 12, 4, 8]) 4 1\n",
      "torch.Size([2, 12, 4, 4])\n",
      "token_type_mat shape torch.Size([2, 12, 4, 4])\n",
      "content score:  torch.Size([2, 12, 4, 4])\n",
      "positional score:  torch.Size([2, 12, 4, 4])\n",
      "token_type score torch.Size([2, 12, 4, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 768])"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = FunnelConfig()\n",
    "fe = FunnelEmbeddings(config)\n",
    "input_ids = torch.LongTensor([[101, 2057, 1012, 102], [101, 1, 2, 102]])\n",
    "input_embeds = fe(input_ids)\n",
    "attention_mask = torch.ones(input_ids.shape, device=input_ids.device)\n",
    "attention_mask = attention_mask.type_as(input_embeds)\n",
    "token_type_ids = torch.zeros(input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
    "\n",
    "seq_len = input_embeds.size(1)\n",
    "token_type_mat = token_type_ids_to_mat(token_type_ids)\n",
    "cls_mask = (F.pad(input_embeds.new_ones([seq_len - 1, seq_len - 1]), (1, 0, 1, 0)))\n",
    "position_embeds = get_position_embeds(seq_len, input_embeds.dtype, input_embeds.device)\n",
    "\n",
    "attention_inputs = (position_embeds, token_type_mat, attention_mask, cls_mask)\n",
    "fra = FunnelRelMultiheadAttention(config, 0)\n",
    "fth, = fra(input_embeds, input_embeds, input_embeds, attention_inputs, output_attentions=False, i=0)\n",
    "fth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SecondType rel pos tensor([ 4,  3,  2,  1,  0, -1, -2, -3])\n",
      "\n",
      "FirstType rel pos tensor([ 3,  2,  1,  0, -1, -2, -3, -4])\n",
      "SecondType rel pos tensor([ 4,  2,  0, -2])\n",
      "\n",
      "FirstType rel pos tensor([ 2,  0, -2, -4])\n",
      "SecondType rel pos tensor([4, 0])\n",
      "\n",
      "torch.Size([2, 4, 12, 64])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "q_head + v shape:  torch.Size([2, 4, 12, 64])\n",
      "q_head:  torch.Size([2, 4, 12, 64])\n",
      "V torch.Size([12, 64])\n",
      "torch.Size([2, 12, 4, 8]) 4 1\n",
      "torch.Size([2, 12, 4, 4])\n",
      "token_type_mat shape torch.Size([2, 12, 4, 4])\n",
      "content score:  torch.Size([2, 12, 4, 4])\n",
      "positional score:  torch.Size([2, 12, 4, 4])\n",
      "token_type score torch.Size([2, 12, 4, 4])\n",
      "Final Print torch.Size([2, 4, 768])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "torch.Size([2, 4, 12, 64])\n",
      "q_head + v shape:  torch.Size([2, 4, 12, 64])\n",
      "q_head:  torch.Size([2, 4, 12, 64])\n",
      "V torch.Size([12, 64])\n",
      "torch.Size([2, 12, 4, 8]) 4 1\n",
      "torch.Size([2, 12, 4, 4])\n",
      "token_type_mat shape torch.Size([2, 12, 4, 4])\n",
      "content score:  torch.Size([2, 12, 4, 4])\n",
      "positional score:  torch.Size([2, 12, 4, 4])\n",
      "token_type score torch.Size([2, 12, 4, 4])\n",
      "Final Print torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "fd(flh, fth, attention_mask, token_type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "\n",
    "from absl import flags\n",
    "import absl.logging as _logging\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "import collections\n",
    "tf.disable_v2_behavior()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/HaoShaochun/Yam/All4NLP/README.md']"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(tf.io.gfile.glob(\"/Users/HaoShaochun/Yam/All4NLP/*.md\"))[0::1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(\"DFSFSDFSD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D', 'F', 'S', 'F', 'S', 'D', 'F', 'S', 'D']"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D', 'F', 'S', 'F', 'S', 'D', 'F', 'S', 'D']"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0::1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = BasicTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['范', '德', '萨', '发', '生', 'i', 'love', 'you', 'cleaning', 'the', 'booking']"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt.convert_text_to_tokens(\"范德萨发生i love you cleaning the booking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitespace_tokenize(text):\n",
    "  \"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"\n",
    "  text = text.strip()\n",
    "  if not text:\n",
    "    return []\n",
    "  tokens = text.split()\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Po'"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicodedata.category(\"，\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "def convert_to_unicode(text):\n",
    "  \"\"\"Converts `text` to Unicode (if it's not already), assuming utf-8 input.\"\"\"\n",
    "  if six.PY3:\n",
    "    if isinstance(text, str):\n",
    "      return text\n",
    "    elif isinstance(text, bytes):\n",
    "      return text.decode(\"utf-8\", \"ignore\")\n",
    "    else:\n",
    "      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "  elif six.PY2:\n",
    "    if isinstance(text, str):\n",
    "      return text.decode(\"utf-8\", \"ignore\")\n",
    "    elif isinstance(text, unicode):\n",
    "      return text\n",
    "    else:\n",
    "      raise ValueError(\"Unsupported string type: %s\" % (type(text)))\n",
    "  else:\n",
    "    raise ValueError(\"Not running on Python2 or Python 3?\")\n",
    "def _is_whitespace(char):\n",
    "  \"\"\"Checks whether `chars` is a whitespace character.\"\"\"\n",
    "  # \\t, \\n, and \\r are technically control characters but we treat them\n",
    "  # as whitespace since they are generally considered as such.\n",
    "  if char == \" \" or char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "    return True\n",
    "  cat = unicodedata.category(char)\n",
    "  if cat == \"Zs\":\n",
    "    return True\n",
    "  return False\n",
    "\n",
    "\n",
    "def _is_control(char):\n",
    "  \"\"\"Checks whether `chars` is a control character.\"\"\"\n",
    "  # These are technically control characters but we count them as whitespace\n",
    "  # characters.\n",
    "  if char == \"\\t\" or char == \"\\n\" or char == \"\\r\":\n",
    "    return False\n",
    "  cat = unicodedata.category(char)\n",
    "  if cat in (\"Cc\", \"Cf\"):\n",
    "    return True\n",
    "  return False\n",
    "\n",
    "\n",
    "def _is_punctuation(char):\n",
    "  \"\"\"Checks whether `chars` is a punctuation character.\"\"\"\n",
    "  cp = ord(char)\n",
    "  # We treat all non-letter/number ASCII as punctuation.\n",
    "  # Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\n",
    "  # Punctuation class but we treat them as punctuation anyways, for\n",
    "  # consistency.\n",
    "  if ((cp >= 33 and cp <= 47) or (cp >= 58 and cp <= 64) or\n",
    "      (cp >= 91 and cp <= 96) or (cp >= 123 and cp <= 126)):\n",
    "    return True\n",
    "  cat = unicodedata.category(char)\n",
    "  if cat.startswith(\"P\"):\n",
    "    return True\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTokenizer(object):\n",
    "  \"\"\"Runs basic tokenization (punctuation splitting, lower casing, etc.).\"\"\"\n",
    "\n",
    "  def __init__(self, do_lower_case=True):\n",
    "    \"\"\"Constructs a BasicTokenizer.\n",
    "    Args:\n",
    "      do_lower_case: Whether to lower case the input.\n",
    "    \"\"\"\n",
    "    self.do_lower_case = do_lower_case\n",
    "\n",
    "  def convert_text_to_tokens(self, text):\n",
    "    \"\"\"Tokenizes a piece of text.\"\"\"\n",
    "    text = convert_to_unicode(text)\n",
    "    text = self._text(text)\n",
    "\n",
    "    # This was added on November 1st, 2018 for the multilingual and Chinese\n",
    "    # models. This is also applied to the English models now, but it doesn't\n",
    "    # matter since the English models were not trained on any Chinese data\n",
    "    # and generally don't have any Chinese data in them (there are Chinese\n",
    "    # characters in the vocabulary because Wikipedia does have some Chinese\n",
    "    # words in the English Wikipedia.).\n",
    "    text = self._tokenize_chinese_chars(text)\n",
    "\n",
    "    orig_tokens = whitespace_tokenize(text)\n",
    "    split_tokens = []\n",
    "    for token in orig_tokens:\n",
    "      if self.do_lower_case:\n",
    "        token = token.lower()\n",
    "        token = self._run_strip_accents(token)\n",
    "      split_tokens.extend(self._run_split_on_punc(token))\n",
    "\n",
    "    output_tokens = whitespace_tokenize(\" \".join(split_tokens))\n",
    "    return output_tokens\n",
    "\n",
    "  def _run_strip_accents(self, text):\n",
    "    \"\"\"Strips accents from a piece of text.\"\"\"\n",
    "    text = unicodedata.normalize(\"NFD\", text)\n",
    "    output = []\n",
    "    for char in text:\n",
    "      cat = unicodedata.category(char)\n",
    "      if cat == \"Mn\":\n",
    "        continue\n",
    "      output.append(char)\n",
    "    return \"\".join(output)\n",
    "\n",
    "  def _run_split_on_punc(self, text):\n",
    "    \"\"\"Splits punctuation on a piece of text.\"\"\"\n",
    "    chars = list(text)\n",
    "    i = 0\n",
    "    start_new_word = True\n",
    "    output = []\n",
    "    while i < len(chars):\n",
    "      char = chars[i]\n",
    "      if _is_punctuation(char):\n",
    "        output.append([char])\n",
    "        start_new_word = True\n",
    "      else:\n",
    "        if start_new_word:\n",
    "          output.append([])\n",
    "        start_new_word = False\n",
    "        output[-1].append(char)\n",
    "      i += 1\n",
    "\n",
    "    return [\"\".join(x) for x in output]\n",
    "\n",
    "  def _tokenize_chinese_chars(self, text):\n",
    "    \"\"\"Adds whitespace around any CJK character.\"\"\"\n",
    "    output = []\n",
    "    for char in text:\n",
    "      cp = ord(char)\n",
    "      if self._is_chinese_char(cp):\n",
    "        output.append(\" \")\n",
    "        output.append(char)\n",
    "        output.append(\" \")\n",
    "      else:\n",
    "        output.append(char)\n",
    "    return \"\".join(output)\n",
    "\n",
    "  def _is_chinese_char(self, cp):\n",
    "    \"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"\n",
    "    # This defines a \"chinese character\" as anything in the CJK Unicode block:\n",
    "    #   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)\n",
    "    #\n",
    "    # Note that the CJK Unicode block is NOT all Japanese and Korean characters,\n",
    "    # despite its name. The modern Korean Hangul alphabet is a different block,\n",
    "    # as is Japanese Hiragana and Katakana. Those alphabets are used to write\n",
    "    # space-separated words, so they are not treated specially and handled\n",
    "    # like the all of the other languages.\n",
    "    if ((cp >= 0x4E00 and cp <= 0x9FFF) or  #\n",
    "        (cp >= 0x3400 and cp <= 0x4DBF) or  #\n",
    "        (cp >= 0x20000 and cp <= 0x2A6DF) or  #\n",
    "        (cp >= 0x2A700 and cp <= 0x2B73F) or  #\n",
    "        (cp >= 0x2B740 and cp <= 0x2B81F) or  #\n",
    "        (cp >= 0x2B820 and cp <= 0x2CEAF) or\n",
    "        (cp >= 0xF900 and cp <= 0xFAFF) or  #\n",
    "        (cp >= 0x2F800 and cp <= 0x2FA1F)):  #\n",
    "      return True\n",
    "\n",
    "    return False\n",
    "\n",
    "  def _text(self, text):\n",
    "    \"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"\n",
    "    output = []\n",
    "    for char in text:\n",
    "      cp = ord(char)\n",
    "      if cp == 0 or cp == 0xfffd or _is_control(char):\n",
    "        continue\n",
    "      if _is_whitespace(char):\n",
    "        output.append(\" \")\n",
    "      else:\n",
    "        output.append(char)\n",
    "    return \"\".join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordpieceTokenizer(object):\n",
    "  \"\"\"Runs WordPiece tokenziation.\"\"\"\n",
    "\n",
    "  def __init__(self, vocab, unk_token=\"<unk>\", max_input_chars_per_word=200):\n",
    "    self.vocab = vocab\n",
    "    self.unk_token = unk_token\n",
    "    self.max_input_chars_per_word = max_input_chars_per_word\n",
    "\n",
    "  def convert_text_to_tokens(self, text):\n",
    "    \"\"\"Tokenizes a piece of text into its word pieces.\n",
    "    This uses a greedy longest-match-first algorithm to perform tokenization\n",
    "    using the given vocabulary.\n",
    "    For example:\n",
    "      input = \"unaffable\"\n",
    "      output = [\"un\", \"##aff\", \"##able\"]\n",
    "    Args:\n",
    "      text: A single token or whitespace separated tokens. This should have\n",
    "        already been passed through `BasicTokenizer.\n",
    "    Returns:\n",
    "      A list of wordpiece tokens.\n",
    "    \"\"\"\n",
    "\n",
    "    text = convert_to_unicode(text)\n",
    "\n",
    "    output_tokens = []\n",
    "    for token in whitespace_tokenize(text):\n",
    "      chars = list(token)\n",
    "      if len(chars) > self.max_input_chars_per_word:\n",
    "        output_tokens.append(self.unk_token)\n",
    "        continue\n",
    "\n",
    "      is_bad = False\n",
    "      start = 0\n",
    "      sub_tokens = []\n",
    "      while start < len(chars):\n",
    "        end = len(chars)\n",
    "        cur_substr = None\n",
    "#         print(start, end)\n",
    "        while start < end:\n",
    "          substr = \"\".join(chars[start:end])\n",
    "#           print(substr)\n",
    "          if start > 0:\n",
    "            substr = \"##\" + substr\n",
    "          if substr in self.vocab:\n",
    "            cur_substr = substr\n",
    "            break\n",
    "          end -= 1\n",
    "        if cur_substr is None:\n",
    "          is_bad = True\n",
    "          break\n",
    "        sub_tokens.append(cur_substr)\n",
    "        start = end\n",
    "\n",
    "      if is_bad:\n",
    "        output_tokens.append(self.unk_token)\n",
    "      else:\n",
    "        output_tokens.extend(sub_tokens)\n",
    "    return output_tokens\n",
    "\n",
    "class FullTokenizer(object):\n",
    "  \"\"\"Runs end-to-end tokenziation.\"\"\"\n",
    "\n",
    "  def __init__(self, vocab_file, do_lower_case=True):\n",
    "    self.vocab = load_vocab(vocab_file)\n",
    "    self.inv_vocab = {v: k for k, v in self.vocab.items()}\n",
    "    self.basic_tokenizer = BasicTokenizer(do_lower_case=do_lower_case)\n",
    "    self.wordpiece_tokenizer = WordpieceTokenizer(vocab=self.vocab)\n",
    "\n",
    "  def convert_text_to_tokens(self, text):\n",
    "    split_tokens = []\n",
    "    for token in self.basic_tokenizer.convert_text_to_tokens(text):\n",
    "      for sub_token in self.wordpiece_tokenizer.convert_text_to_tokens(token):\n",
    "        split_tokens.append(sub_token)\n",
    "\n",
    "    return split_tokens\n",
    "\n",
    "  def get_token_id(self, token):\n",
    "    return self.vocab[token]\n",
    "\n",
    "  def convert_tokens_to_ids(self, tokens):\n",
    "    return convert_by_vocab(self.vocab, tokens)\n",
    "\n",
    "  def convert_ids_to_tokens(self, ids):\n",
    "    return convert_by_vocab(self.inv_vocab, ids)\n",
    "\n",
    "  def convert_text_to_ids(self, text):\n",
    "    tokens = self.convert_text_to_tokens(text)\n",
    "    return self.convert_tokens_to_ids(tokens)\n",
    "\n",
    "  def convert_ids_to_text(self, ids):\n",
    "    tokens = self.convert_ids_to_tokens(ids)\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "  def is_start_id(self, token_id):\n",
    "    token = self.inv_vocab[token_id]\n",
    "    return not token.startswith(\"##\")\n",
    "\n",
    "  def is_func_id(self, token_id):\n",
    "    token = self.inv_vocab[token_id]\n",
    "    return self.is_func_token(token)\n",
    "\n",
    "  def is_func_token(self, token):\n",
    "    return token != \"<unk>\" and token.startswith(\"<\") and token.endswith(\">\")\n",
    "\n",
    "  def get_vocab_size(self):\n",
    "    return len(self.vocab)\n",
    "\n",
    "def load_vocab(vocab_file):\n",
    "  \"\"\"Loads a vocabulary file into a dictionary.\"\"\"\n",
    "  vocab = collections.OrderedDict()\n",
    "  with tf.io.gfile.GFile(vocab_file, \"r\") as reader:\n",
    "    while True:\n",
    "      token = convert_to_unicode(reader.readline())\n",
    "      if not token:\n",
    "        break\n",
    "      token = token.strip()\n",
    "      if token not in vocab:\n",
    "        vocab[token] = len(vocab)\n",
    "  return vocab\n",
    "\n",
    "def convert_by_vocab(vocab, items):\n",
    "  \"\"\"Converts a sequence of [tokens|ids] using the vocab.\"\"\"\n",
    "  output = []\n",
    "  for item in items:\n",
    "    output.append(vocab[item])\n",
    "  return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lovingx\n",
      "0 7\n",
      "lovingx\n",
      "loving\n",
      "lovin\n",
      "lovi\n",
      "lov\n",
      "lo\n",
      "2 7\n",
      "vingx\n",
      "ving\n",
      "6 7\n",
      "x\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lo', '##ving', '##x']"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wt = WordpieceTokenizer(vocab)\n",
    "wt.convert_text_to_tokens(\"lovingx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"##ving\" in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pnlp.read_lines(\"/Volumes/YamHd/Lab/1Models/chinese_rbt3_pytorch/vocab.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bins = np.histogram([np.random.randint(1000) for i in range(100)],\n",
    "                            bins=[0, 64, 128, 256, 512, 1024, 2048, 102400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_indices = np.random.permutation(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True])"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logical_not([True, True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PrepareData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_data(input_paths, tokenizer):\n",
    "  \"\"\"Load data and call corresponding create_func.\"\"\"\n",
    "  input_shards = []\n",
    "\n",
    "  # working structure used to store each document\n",
    "  input_data, sent_ids = [], []\n",
    "  end_of_doc = False\n",
    "\n",
    "  # monitor doc length and number of tokens\n",
    "  doc_length = []\n",
    "  total_num_tok = 0\n",
    "\n",
    "  for input_path in input_paths:\n",
    "    sent_id, line_cnt = True, 0\n",
    "\n",
    "    tf.logging.info(\"Start processing %s\", input_path)\n",
    "    for line in tf.io.gfile.GFile(input_path):\n",
    "      if line_cnt % 100000 == 0:\n",
    "        tf.logging.info(\"Loading line %d\", line_cnt)\n",
    "\n",
    "      if not line.strip():\n",
    "        # encounter an empty line (end of a document)\n",
    "        end_of_doc = True\n",
    "        cur_sent = []\n",
    "      else:\n",
    "        cur_sent = tokenizer.convert_text_to_ids(line.strip())\n",
    "\n",
    "      if cur_sent:\n",
    "        input_data.extend(cur_sent)\n",
    "        sent_ids.extend([sent_id] * len(cur_sent))\n",
    "        sent_id = not sent_id\n",
    "\n",
    "      if end_of_doc:\n",
    "        # monitor over doc lengths\n",
    "        doc_length.append(len(input_data))\n",
    "\n",
    "        # only retain docs longer than `min_doc_len`\n",
    "        if len(input_data) >= max(1, 1):\n",
    "          input_data = np.array(input_data, dtype=np.int64)\n",
    "          sent_ids = np.array(sent_ids, dtype=np.bool)\n",
    "          input_shards.append((input_data, sent_ids))\n",
    "          total_num_tok += len(input_data)\n",
    "\n",
    "        # refresh working structs\n",
    "        input_data, sent_ids = [], []\n",
    "        end_of_doc = False\n",
    "\n",
    "      line_cnt += 1\n",
    "\n",
    "    tf.logging.info(\"Finish %s with %d lines.\", input_path, line_cnt)\n",
    "\n",
    "  print(input_shards)\n",
    "  tf.logging.info(\"[Task %d] Total number tokens: %d\", 0,\n",
    "                  total_num_tok)\n",
    "\n",
    "  hist, bins = np.histogram(doc_length,\n",
    "                            bins=[0, 64, 128, 256, 512, 1024, 2048, 102400])\n",
    "  percent = hist / np.sum(hist)\n",
    "  tf.logging.info(\"***** Doc length histogram *****\")\n",
    "  for pct, l, r in zip(percent, bins[:-1], bins[1:]):\n",
    "    tf.logging.info(\"  - [%d, %d]: %.4f\", l, r, pct)\n",
    "\n",
    "  # Randomly shuffle input shards (with a fixed but unique random seed)\n",
    "  np.random.seed(100 * 0 + 0)\n",
    "  perm_indices = np.random.permutation(len(input_shards))\n",
    "\n",
    "  input_data_list, sent_ids_list = [], []\n",
    "  prev_sent_id = None\n",
    "  for perm_idx in perm_indices:\n",
    "    input_data, sent_ids = input_shards[perm_idx]\n",
    "    tf.logging.debug(\"Idx %d: data %s sent %s\", perm_idx,\n",
    "                     input_data.shape, sent_ids.shape)\n",
    "    # make sure the `send_ids[0] == not prev_sent_id`\n",
    "    if prev_sent_id is not None and sent_ids[0] == prev_sent_id:\n",
    "      sent_ids = np.logical_not(sent_ids)\n",
    "\n",
    "    # append to temporary list\n",
    "    input_data_list.append(input_data)\n",
    "    sent_ids_list.append(sent_ids)\n",
    "\n",
    "    # update `prev_sent_id`\n",
    "    prev_sent_id = sent_ids[-1]\n",
    "\n",
    "  # concat into a flat np.ndarray\n",
    "  input_data = np.concatenate(input_data_list)\n",
    "  sent_ids = np.concatenate(sent_ids_list)\n",
    "  return (input_data, sent_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_file = \"/Volumes/YamHd/Lab/1Models/chinese_rbt3_pytorch/vocab.txt\"\n",
    "tokenizer = FullTokenizer(vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'lv', '##oe', 'you']"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_text_to_tokens(\"i lvoe you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[151, 8289, 10115, 8357]"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_text_to_ids(\"i lvoe you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = sorted(tf.io.gfile.glob(\"./data/*.txt\"))\n",
    "task_file_paths = file_paths[0::1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9656, 8148, 9064, 11759, 9519, 8332, 8181, 12220, 119]"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_text_to_ids(\"Doc1 another paragraph.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start processing ./data/funnel.txt\n",
      "INFO:tensorflow:Loading line 0\n",
      "INFO:tensorflow:Finish ./data/funnel.txt with 24 lines.\n",
      "[(array([ 9656,  8148,  8975,  8174, 13017,  8168,  9575, 12827,   118,\n",
      "         162, 10477,  8118, 12725,  8755,  8995,   162, 11944,  8303,\n",
      "        8663,  8174, 10245, 10862,  8332, 11336,  8857,   119,   165,\n",
      "        8963,  8370, 10253, 11418, 10050,  8179,  8847,  8326,  9273,\n",
      "        9683,   143,   107, 10234,  8957, 11762,   107,  8134,  9401,\n",
      "        8354,  8511,   119,  8217,  9470, 12183,  8877,   117, 11136,\n",
      "        8995, 13050, 11927, 10474,  8118,   131,   133,   147,  9133,\n",
      "         135,  8330,  8533,  8914,  8829,  8221,   118, 10110, 11227,\n",
      "        9980, 10936,  8118,   119]), array([ True,  True, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False])), (array([ 9656,  8144,  8174, 10234,  8957, 11762,  8310,  9796, 13075,\n",
      "        8436,  9796, 10203,  9345,  8303,  8256, 10110,  8174,  9684,\n",
      "        9264,   119,  8281,  8174, 12132, 12126,  8168,   117,  8898,\n",
      "        8429, 12733,  8118,  8228,  9486, 11207,  8196,   163,  8727,\n",
      "        8838,  8196, 11233,  8303,   162,  8829,  8154,   119,   133,\n",
      "         147,  9133,   135,  8174, 11685,  9808,  8620,  8168,  9264,\n",
      "        8663,  8174, 10245, 10862,  8332, 11336,  8857,  8281, 13233,\n",
      "        9000,   119]), array([ True,  True, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False])), (array([ 9656,  8152,   113,   107,  9796, 10203,  8641,  9844, 11762,\n",
      "         107,   114,  8310,  8533,  8914,  8829,  8303,   119,   119,\n",
      "        8174, 10234,  8957, 11762,  8310, 10564,  8303,  8303,   119,\n",
      "         133,   147,  9133,   135, 11668,  8168,  8281,  8174, 10380,\n",
      "        9796,  9049, 12865,  8511, 11927, 10474,  8118,   117,  8997,\n",
      "        8376,  9197,  8510, 10380,  9178,  8118,  8205,  8282,  8727,\n",
      "        8372, 11522,  9233, 11112,  8118,   131,   119]), array([ True,  True, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False])), (array([ 9656,  8159,  9684,   118, 10110,  9233, 11112,  8118,   131,\n",
      "        8554,  9178, 10110,  8910, 10079, 11211,  8174,  9519, 13185,\n",
      "       12017,  8205,  8174,  9684,  9575, 12827,   118,   162, 10477,\n",
      "        8118, 12725,  8196,  9264,   119,   113,   107,  9447, 10802,\n",
      "        8180,   107,   116,   107,  9333, 10260,  8180,   107,   114,\n",
      "         119, 10288,  8513,  8174,  8792, 12579,  8333,  9401, 11874,\n",
      "        8291, 10208,  9007,  8625, 10631, 11603,  8995,  8847,  8788,\n",
      "       11667,   119,   133,   147,  9133,   135,  8847,  8383,  8620,\n",
      "        8168,  8217, 10474,  8118,  8429, 10931,  8333,  8228,  8847,\n",
      "       10254,   162,  9570,  8417, 11603,   119]), array([ True,  True, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "        True,  True,  True,  True,  True,  True, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False]))]\n",
      "INFO:tensorflow:[Task 0] Total number tokens: 289\n",
      "INFO:tensorflow:***** Doc length histogram *****\n",
      "INFO:tensorflow:  - [0, 64]: 0.2500\n",
      "INFO:tensorflow:  - [64, 128]: 0.7500\n",
      "INFO:tensorflow:  - [128, 256]: 0.0000\n",
      "INFO:tensorflow:  - [256, 512]: 0.0000\n",
      "INFO:tensorflow:  - [512, 1024]: 0.0000\n",
      "INFO:tensorflow:  - [1024, 2048]: 0.0000\n",
      "INFO:tensorflow:  - [2048, 102400]: 0.0000\n"
     ]
    }
   ],
   "source": [
    "data, sent_ids = create_pretrain_data(task_file_paths, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_a_and_b(data, sent_ids, begin_idx, tot_len):\n",
    "  \"\"\"Split two segments from `data` starting from the index `begin_idx`.\"\"\"\n",
    "\n",
    "  data_len = data.shape[0]\n",
    "  if begin_idx + tot_len >= data_len:\n",
    "    tf.logging.info(\"Not enough data: \"\n",
    "                    \"begin_idx %d + tot_len %d >= data_len %d\",\n",
    "                    begin_idx, tot_len, data_len)\n",
    "    return None\n",
    "\n",
    "  end_idx = begin_idx + 1\n",
    "  cut_points = []\n",
    "  while end_idx < data_len:\n",
    "    if sent_ids[end_idx] != sent_ids[end_idx - 1]:\n",
    "      if end_idx - begin_idx >= tot_len: break\n",
    "      cut_points.append(end_idx)\n",
    "    end_idx += 1\n",
    "\n",
    "  a_begin = begin_idx\n",
    "  if not cut_points or random.random() < 0.5:\n",
    "    # negative pair\n",
    "    label = 0\n",
    "    if not cut_points:\n",
    "      a_end = end_idx\n",
    "    else:\n",
    "      a_end = random.choice(cut_points)\n",
    "\n",
    "    b_len = max(1, tot_len - (a_end - a_begin))\n",
    "    b_begin = random.randint(0, data_len - b_len)\n",
    "    b_end = b_begin + b_len\n",
    "\n",
    "    # locate a complete sentence for `b`\n",
    "    while b_begin > 0 and sent_ids[b_begin - 1] == sent_ids[b_begin]:\n",
    "      b_begin -= 1\n",
    "    while b_end < data_len and sent_ids[b_end - 1] == sent_ids[b_end]:\n",
    "      b_end += 1\n",
    "\n",
    "    new_begin = a_end\n",
    "  else:\n",
    "    # positive pair\n",
    "    label = 1\n",
    "    a_end = random.choice(cut_points)\n",
    "    b_begin = a_end\n",
    "    b_end = end_idx\n",
    "\n",
    "    new_begin = b_end\n",
    "\n",
    "  # truncate both a & b\n",
    "  while a_end - a_begin + b_end - b_begin > tot_len:\n",
    "    # truncate a (only right)\n",
    "    if a_end - a_begin > b_end - b_begin:\n",
    "      a_end -= 1\n",
    "    # truncate b (both left and right)\n",
    "    else:\n",
    "      if random.random() < 0.5:\n",
    "        b_end -= 1\n",
    "      else:\n",
    "        b_begin += 1\n",
    "\n",
    "  ret = [data[a_begin: a_end], data[b_begin: b_end], label, new_begin]\n",
    "\n",
    "  return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([9656, 8152]), array([ 107,  114, 8310]), 1, 18]"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_split_a_and_b(\n",
    "        data,\n",
    "        sent_ids,\n",
    "        begin_idx=0,\n",
    "        tot_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9656,  8152,   113,   107,  9796, 10203,  8641,  9844, 11762,\n",
       "         107,   114,  8310,  8533,  8914,  8829,  8303,   119,   119,\n",
       "        8174, 10234,  8957, 11762,  8310, 10564,  8303,  8303,   119,\n",
       "         133,   147,  9133,   135, 11668,  8168,  8281,  8174, 10380,\n",
       "        9796,  9049, 12865,  8511, 11927, 10474,  8118,   117,  8997,\n",
       "        8376,  9197,  8510, 10380,  9178,  8118,  8205,  8282,  8727,\n",
       "        8372, 11522,  9233, 11112,  8118,   131,   119,  9656,  8159,\n",
       "        9684,   118, 10110,  9233, 11112,  8118,   131,  8554,  9178,\n",
       "       10110,  8910, 10079, 11211,  8174,  9519, 13185, 12017,  8205,\n",
       "        8174,  9684,  9575, 12827,   118,   162, 10477,  8118, 12725,\n",
       "        8196,  9264,   119,   113,   107,  9447, 10802,  8180,   107,\n",
       "         116,   107,  9333, 10260,  8180,   107,   114,   119, 10288,\n",
       "        8513,  8174,  8792, 12579,  8333,  9401, 11874,  8291, 10208,\n",
       "        9007,  8625, 10631, 11603,  8995,  8847,  8788, 11667,   119,\n",
       "         133,   147,  9133,   135,  8847,  8383,  8620,  8168,  8217,\n",
       "       10474,  8118,  8429, 10931,  8333,  8228,  8847, 10254,   162,\n",
       "        9570,  8417, 11603,   119,  9656,  8144,  8174, 10234,  8957,\n",
       "       11762,  8310,  9796, 13075,  8436,  9796, 10203,  9345,  8303,\n",
       "        8256, 10110,  8174,  9684,  9264,   119,  8281,  8174, 12132,\n",
       "       12126,  8168,   117,  8898,  8429, 12733,  8118,  8228,  9486,\n",
       "       11207,  8196,   163,  8727,  8838,  8196, 11233,  8303,   162,\n",
       "        8829,  8154,   119,   133,   147,  9133,   135,  8174, 11685,\n",
       "        9808,  8620,  8168,  9264,  8663,  8174, 10245, 10862,  8332,\n",
       "       11336,  8857,  8281, 13233,  9000,   119,  9656,  8148,  8975,\n",
       "        8174, 13017,  8168,  9575, 12827,   118,   162, 10477,  8118,\n",
       "       12725,  8755,  8995,   162, 11944,  8303,  8663,  8174, 10245,\n",
       "       10862,  8332, 11336,  8857,   119,   165,  8963,  8370, 10253,\n",
       "       11418, 10050,  8179,  8847,  8326,  9273,  9683,   143,   107,\n",
       "       10234,  8957, 11762,   107,  8134,  9401,  8354,  8511,   119,\n",
       "        8217,  9470, 12183,  8877,   117, 11136,  8995, 13050, 11927,\n",
       "       10474,  8118,   131,   133,   147,  9133,   135,  8330,  8533,\n",
       "        8914,  8829,  8221,   118, 10110, 11227,  9980, 10936,  8118,\n",
       "         119])"
      ]
     },
     "execution_count": 827,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True,  True, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
